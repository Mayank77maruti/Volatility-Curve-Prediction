import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (Input, LSTM, Dense, Dropout, BatchNormalization, 
                                   MultiHeadAttention, GlobalAveragePooling1D, 
                                   Concatenate, LayerNormalization, Add)
from tensorflow.keras.optimizers import AdamW
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import TimeSeriesSplit
import os
import time
import gc
from functools import lru_cache
import warnings
warnings.filterwarnings('ignore')

class OptimizedVolatilityPredictor:
    def __init__(self, sequence_length=30, lstm_units=128, attention_heads=8):
        self.sequence_length = sequence_length
        self.lstm_units = lstm_units
        self.attention_heads = attention_heads
        self.scaler = None
        self.model = None
        self.feature_columns = []
        self.target_columns = []
        self.min_timestamp = None
        
        # Optimization settings
        self.batch_size = 512  # Larger batch size for better GPU utilization
        self.prefetch_buffer = tf.data.AUTOTUNE
        
    def load_data(self, train_path, test_path, sample_sub_path):
        """Optimized data loading with memory management"""
        print("Loading datasets with optimized memory usage...")
        
        # Load parquet files without dtype specification (not supported)
        self.train_df = pd.read_parquet(train_path)
        self.test_df = pd.read_parquet(test_path)
        self.sample_sub = pd.read_csv(sample_sub_path)
        
        # Optimize dtypes after loading
        float_cols = ['underlying_price', 'atm_iv', 'high', 'low', 'open', 'close']
        for col in float_cols:
            if col in self.train_df.columns:
                self.train_df[col] = self.train_df[col].astype('float32')
            if col in self.test_df.columns:
                self.test_df[col] = self.test_df[col].astype('float32')
        
        # Convert timestamp once and store min
        self.train_df['timestamp'] = pd.to_datetime(self.train_df['timestamp'])
        self.test_df['timestamp'] = pd.to_datetime(self.test_df['timestamp'])
        self.min_timestamp = min(self.train_df['timestamp'].min(), self.test_df['timestamp'].min())
        
        print(f"Train shape: {self.train_df.shape}, Test shape: {self.test_df.shape}")
        
    @lru_cache(maxsize=128)
    def _get_rolling_stats(self, series_hash, window):
        """Cached rolling statistics computation"""
        # This would be used with hashable series representations
        pass
        
    def engineer_features_vectorized(self, df):
        """Vectorized feature engineering for better performance"""
        print("Engineering features with vectorized operations...")
        df = df.copy()
        
        # Vectorized timestamp features
        df['seconds'] = (df['timestamp'] - self.min_timestamp).dt.total_seconds().astype('float32')
        df['hour'] = df['timestamp'].dt.hour.astype('int8')
        df['minute'] = df['timestamp'].dt.minute.astype('int8')
        df['day_of_week'] = df['timestamp'].dt.dayofweek.astype('int8')
        df['is_weekend'] = (df['day_of_week'] >= 5).astype('int8')
        
        # Vectorized time features
        df['time_of_day'] = (df['hour'] + df['minute']/60).astype('float32')
        df['sin_hour'] = np.sin(2 * np.pi * df['hour'] / 24).astype('float32')
        df['cos_hour'] = np.cos(2 * np.pi * df['hour'] / 24).astype('float32')
        
        # Price dynamics with numpy operations
        if 'underlying_price' in df.columns:
            price = df['underlying_price'].values
            
            # Efficient log returns
            log_returns = np.diff(np.log(price), prepend=np.nan)
            df['log_return'] = log_returns.astype('float32')
            
            # Vectorized rolling operations using pandas rolling (optimized)
            windows = [5, 15, 30, 60]
            for window in windows:
                # Use pandas optimized rolling
                df[f'volatility_{window}s'] = df['log_return'].rolling(
                    window, min_periods=1).std().astype('float32')
                df[f'return_ma_{window}s'] = df['underlying_price'].rolling(
                    window, min_periods=1).mean().astype('float32')
                df[f'price_momentum_{window}s'] = (
                    df['underlying_price'] / df[f'return_ma_{window}s'] - 1
                ).astype('float32')
            
            # Efficient price changes
            df['price_change_1s'] = np.diff(price, prepend=0).astype('float32')
            df['price_accel'] = np.diff(df['price_change_1s'], prepend=0).astype('float32')
            
            # Technical indicators
            if all(col in df.columns for col in ['high', 'low', 'open', 'close']):
                df['high_low_spread'] = (df['high'] - df['low']).astype('float32')
                df['close_open_spread'] = (df['close'] - df['open']).astype('float32')
                df['true_range'] = np.maximum.reduce([
                    df['high'] - df['low'],
                    np.abs(df['high'] - df['close'].shift(1)),
                    np.abs(df['low'] - df['close'].shift(1))
                ]).astype('float32')
        
        # Optimized volume features
        volume_cols = [c for c in df.columns if 'volume' in c.lower()]
        for col in volume_cols:
            if df[col].dtype != 'float32':
                df[col] = df[col].astype('float32')
            df[f'{col}_change'] = df[col].diff().astype('float32')
            
            # Only compute essential rolling stats
            df[f'{col}_ma_15s'] = df[col].rolling(15, min_periods=1).mean().astype('float32')
            df[f'{col}_std_15s'] = df[col].rolling(15, min_periods=1).std().astype('float32')
        
        # ATM IV features
        if 'atm_iv' in df.columns:
            df['atm_iv_change'] = df['atm_iv'].diff().astype('float32')
            df['atm_iv_pct_change'] = df['atm_iv'].pct_change().astype('float32')
            df['atm_iv_zscore'] = ((df['atm_iv'] - df['atm_iv'].rolling(30, min_periods=1).mean()) / 
                                  df['atm_iv'].rolling(30, min_periods=1).std()).astype('float32')
        
        # Fill NaNs using forward then backward fill (updated method)
        df = df.ffill().bfill().fillna(0)
        
        # Replace inf values efficiently
        df = df.replace([np.inf, -np.inf], 0)
        
        # Memory optimization: convert to appropriate dtypes
        for col in df.select_dtypes(include=['float64']).columns:
            df[col] = df[col].astype('float32')
            
        return df
    
    def prepare_data_optimized(self):
        """Memory-efficient data preparation"""
        print("Preparing data with memory optimization...")
        
        # Identify targets
        self.target_columns = [col for col in self.train_df.columns 
                             if col.startswith(('call_iv_', 'put_iv_'))]
        
        # Select features more efficiently
        exclude_cols = set(self.target_columns + ['timestamp'])
        feature_cols = [col for col in self.train_df.columns 
                       if col not in exclude_cols and self.train_df[col].dtype in ['float32', 'float64', 'int8', 'int16', 'int32']]
        
        self.feature_columns = feature_cols
        print(f"Using {len(self.feature_columns)} features for {len(self.target_columns)} targets")
        
        # Efficient scaling
        X_train = self.train_df[feature_cols].values.astype('float32')
        y_train = self.train_df[self.target_columns].values.astype('float32')
        
        # Use RobustScaler for better outlier handling
        self.scaler = RobustScaler()
        X_train_scaled = self.scaler.fit_transform(X_train).astype('float32')
        
        # Optimized sequence creation using numpy
        seq_len = self.sequence_length
        n_samples = len(X_train_scaled) - seq_len
        n_features = X_train_scaled.shape[1]
        n_targets = y_train.shape[1]
        
        # Pre-allocate arrays
        X_sequences = np.empty((n_samples, seq_len, n_features), dtype='float32')
        y_sequences = np.empty((n_samples, n_targets), dtype='float32')
        
        # Vectorized sequence creation
        for i in range(n_samples):
            X_sequences[i] = X_train_scaled[i:i+seq_len]
            y_sequences[i] = y_train[i+seq_len]
        
        print(f"Sequences shape: {X_sequences.shape}, Targets shape: {y_sequences.shape}")
        
        # Memory cleanup
        del X_train, X_train_scaled, y_train
        gc.collect()
        
        return X_sequences, y_sequences
    
    def build_optimized_model(self, input_shape, output_dim):
        """Enhanced model architecture with better optimization"""
        inputs = Input(shape=input_shape, dtype='float32')
        
        # Input layer normalization
        x = LayerNormalization()(inputs)
        
        # First LSTM block with residual connections
        lstm1 = LSTM(self.lstm_units, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)(x)
        lstm1_norm = LayerNormalization()(lstm1)
        
        # Second LSTM block
        lstm2 = LSTM(self.lstm_units, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)(lstm1_norm)
        lstm2_norm = LayerNormalization()(lstm2)
        
        # Multi-head attention with residual connection
        attention_output = MultiHeadAttention(
            num_heads=self.attention_heads,
            key_dim=self.lstm_units // self.attention_heads,
            dropout=0.1
        )(lstm2_norm, lstm2_norm)
        
        # Residual connection
        attention_residual = Add()([lstm2_norm, attention_output])
        attention_norm = LayerNormalization()(attention_residual)
        
        # Global pooling for sequence summarization
        pooled = GlobalAveragePooling1D()(attention_norm)
        
        # Dense layers with batch normalization
        dense1 = Dense(self.lstm_units * 2, activation='swish')(pooled)
        dense1_norm = BatchNormalization()(dense1)
        dense1_drop = Dropout(0.3)(dense1_norm)
        
        dense2 = Dense(self.lstm_units, activation='swish')(dense1_drop)
        dense2_norm = BatchNormalization()(dense2)
        dense2_drop = Dropout(0.2)(dense2_norm)
        
        # Output layer with positive constraint
        outputs = Dense(output_dim, activation='softplus', name='iv_output')(dense2_drop)
        
        model = Model(inputs, outputs, name='OptimizedVolatilityPredictor')
        
        # Use AdamW optimizer with gradient clipping
        optimizer = AdamW(
            learning_rate=0.001,
            weight_decay=0.01,
            clipnorm=1.0  # Use only clipnorm, not both clipnorm and global_clipnorm
        )
        
        model.compile(
            optimizer=optimizer,
            loss=self.advanced_loss,
            metrics=['mae']
        )
        
        return model
    
    def advanced_loss(self, y_true, y_pred):
        """Advanced loss function with multiple components"""
        # MSE component
        mse = tf.keras.losses.MeanSquaredError()(y_true, y_pred)
        
        # MAE component for robustness
        mae = tf.keras.losses.MeanAbsoluteError()(y_true, y_pred)
        
        # Huber loss component for outlier robustness
        huber = tf.keras.losses.Huber(delta=0.1)(y_true, y_pred)
        
        # Volatility-specific constraints
        # Penalize negative predictions more heavily
        negative_penalty = tf.reduce_mean(tf.maximum(0.0, -y_pred) * 10)
        
        # Smoothness penalty (adjacent predictions should be similar)
        smoothness_penalty = tf.reduce_mean(tf.square(y_pred[:, 1:] - y_pred[:, :-1]))
        
        # Combined loss
        total_loss = (0.4 * mse + 0.3 * mae + 0.2 * huber + 
                     0.05 * negative_penalty + 0.05 * smoothness_penalty)
        
        return total_loss
    
    def create_optimized_dataset(self, X, y, batch_size, shuffle=True):
        """Create optimized tf.data.Dataset"""
        dataset = tf.data.Dataset.from_tensor_slices((X, y))
        
        if shuffle:
            dataset = dataset.shuffle(buffer_size=10000, seed=42)
            
        dataset = dataset.batch(batch_size, drop_remainder=False)
        dataset = dataset.prefetch(self.prefetch_buffer)
        
        return dataset
    
    def train_model_optimized(self, X, y):
        """Optimized training with better validation strategy"""
        print("\nStarting optimized training...")
        
        # Time series split with larger validation sets
        tscv = TimeSeriesSplit(n_splits=3, test_size=len(X)//5)
        best_val_loss = float('inf')
        best_model_path = 'best_model.weights.h5'  # CORRECTED FILENAME
        
        fold_results = []
        
        for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):
            print(f"\n{'='*50}")
            print(f"Training fold {fold+1}/{tscv.n_splits}")
            print(f"Train samples: {len(train_idx)}, Val samples: {len(val_idx)}")
            
            X_train, X_val = X[train_idx], X[val_idx]
            y_train, y_val = y[train_idx], y[val_idx]
            
            # Create optimized datasets
            train_dataset = self.create_optimized_dataset(X_train, y_train, self.batch_size, shuffle=True)
            val_dataset = self.create_optimized_dataset(X_val, y_val, self.batch_size, shuffle=False)
            
            # Build model
            model = self.build_optimized_model(
                input_shape=(self.sequence_length, len(self.feature_columns)),
                output_dim=len(self.target_columns)
            )
            
            # Enhanced callbacks
            callbacks = [
                EarlyStopping(
                    monitor='val_loss', 
                    patience=15, 
                    restore_best_weights=True,
                    min_delta=1e-6
                ),
                ReduceLROnPlateau(
                    monitor='val_loss',
                    factor=0.5, 
                    patience=7, 
                    min_lr=1e-7,
                    verbose=1
                ),
                ModelCheckpoint(
                    best_model_path,  # NOW CORRECT
                    monitor='val_loss',
                    save_best_only=True,
                    save_weights_only=True,
                    verbose=0
                )
            ]
            
            # Training with optimized parameters
            history = model.fit(
                train_dataset,
                validation_data=val_dataset,
                epochs=100,
                callbacks=callbacks,
                verbose=1
            )
            
            # Track results
            val_loss = min(history.history['val_loss'])
            fold_results.append(val_loss)
            
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                self.model = model
                print(f"✓ New best model with val_loss: {best_val_loss:.6f}")
            
            # Memory cleanup
            del X_train, X_val, y_train, y_val, train_dataset, val_dataset
            if fold < tscv.n_splits - 1 and os.path.exists(best_model_path):
                os.remove(best_model_path)  # Cleanup intermediate weights
            gc.collect()
        
        print(f"\n{'='*50}")
        print(f"Cross-validation results: {fold_results}")
        print(f"Mean CV loss: {np.mean(fold_results):.6f} ± {np.std(fold_results):.6f}")
        print(f"Best validation loss: {best_val_loss:.6f}")
        
        # Final model loading (keep this)
        if os.path.exists(best_model_path):
            self.model.load_weights(best_model_path)
            os.remove(best_model_path)  # Final cleanup
    
    def create_test_sequences_optimized(self, df):
        """Optimized test sequence creation"""
        # Ensure all features exist
        for col in self.feature_columns:
            if col not in df.columns:
                df[col] = 0.0
        
        X_test = df[self.feature_columns].values.astype('float32')
        X_test_scaled = self.scaler.transform(X_test)
        
        # Create sequence efficiently
        if len(X_test_scaled) >= self.sequence_length:
            sequence = X_test_scaled[-self.sequence_length:]
        else:
            # Pad with zeros if insufficient data
            padding_size = self.sequence_length - len(X_test_scaled)
            padding = np.zeros((padding_size, X_test_scaled.shape[1]), dtype='float32')
            sequence = np.vstack([padding, X_test_scaled])
        
        return sequence.reshape(1, self.sequence_length, -1)
    
    def predict_optimized(self, test_df):
        """Optimized prediction with batch processing"""
        print("Generating predictions...")
        
        # Create test sequences
        X_test_seq = self.create_test_sequences_optimized(test_df)
        
        # Predict (remove GPU-specific device placement for CPU compatibility)
        predictions = self.model.predict(X_test_seq, batch_size=1, verbose=0)
        
        # Create result DataFrame
        pred_df = pd.DataFrame(predictions, columns=self.target_columns)
        pred_df['timestamp'] = test_df['timestamp'].iloc[-1]
        
        # Apply reasonable bounds with volatility smile constraints
        pred_df[self.target_columns] = pred_df[self.target_columns].clip(0.05, 2.0)
        
        return pred_df
    
    def create_submission_optimized(self, predictions):
        """Optimized submission creation with smart filling"""
        print("Creating optimized submission...")
        
        submission_df = self.sample_sub.copy()
        iv_cols = [col for col in submission_df.columns if col != 'timestamp']
        
        # Fill available predictions
        for col in self.target_columns:
            if col in submission_df.columns:
                submission_df[col] = predictions[col].iloc[0]
        
        # Smart interpolation for missing strikes
        missing_cols = [col for col in iv_cols if col not in self.target_columns]
        
        for col in missing_cols:
            if col.startswith(('call_iv_', 'put_iv_')):
                try:
                    option_type = 'call_iv_' if col.startswith('call_iv_') else 'put_iv_'
                    target_strike = int(col.split('_')[-1])
                    
                    # Find available strikes for same option type
                    available_cols = [c for c in self.target_columns if c.startswith(option_type)]
                    if available_cols:
                        strikes_values = [(int(c.split('_')[-1]), predictions[c].iloc[0]) 
                                        for c in available_cols]
                        strikes_values.sort()
                        
                        # Linear interpolation/extrapolation
                        strikes = [sv[0] for sv in strikes_values]
                        values = [sv[1] for sv in strikes_values]
                        
                        interpolated_value = np.interp(target_strike, strikes, values)
                        submission_df[col] = interpolated_value
                    else:
                        submission_df[col] = 0.2  # Fallback
                except Exception as e:
                    print(f"Warning: Could not interpolate {col}, using default: {e}")
                    submission_df[col] = 0.2
            else:
                submission_df[col] = 0.2
        
        # Final validation and cleanup
        submission_df = submission_df.fillna(0.2)
        submission_df[iv_cols] = submission_df[iv_cols].clip(0.05, 2.0)
        
        # Save submission
        output_path = "submission.csv"
        submission_df.to_csv(output_path, index=False)
        
        print(f"✓ Submission saved: {output_path}")
        print(f"Shape: {submission_df.shape}, NaN count: {submission_df.isna().sum().sum()}")
        print(f"IV range: [{submission_df[iv_cols].min().min():.3f}, {submission_df[iv_cols].max().max():.3f}]")
        
        return submission_df

def optimize_tensorflow():
    """Configure TensorFlow for optimal performance"""
    # For CPU-only systems, skip mixed precision as it may cause issues
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        # Enable mixed precision for faster training (GPU only)
        policy = tf.keras.mixed_precision.Policy('mixed_float16')
        tf.keras.mixed_precision.set_global_policy(policy)
        
        # Enable XLA compilation
        tf.config.optimizer.set_jit(True)
        
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print(f"✓ Configured {len(gpus)} GPU(s) with memory growth")
        except RuntimeError as e:
            print(f"GPU configuration error: {e}")
    else:
        print("• Running on CPU - skipping GPU-specific optimizations")
    
    # Optimize threading for CPU
    tf.config.threading.set_intra_op_parallelism_threads(0)  # Use all available cores
    tf.config.threading.set_inter_op_parallelism_threads(0)

def main():
    """Optimized main execution"""
    print("🚀 Starting Optimized Volatility Prediction")
    print("="*60)
    
    # Optimize TensorFlow
    optimize_tensorflow()
    
    # File paths
    current_dir = os.getcwd()
    train_path = os.path.join(current_dir, "train_data.parquet")
    test_path = os.path.join(current_dir, "test_data.parquet")
    sample_sub_path = os.path.join(current_dir, "sample_submission.csv")
    
    # Initialize predictor with optimized parameters
    predictor = OptimizedVolatilityPredictor(
        sequence_length=30, 
        lstm_units=128, 
        attention_heads=8
    )
    
    total_start = time.time()
    
    try:
        # Load data
        start_time = time.time()
        predictor.load_data(train_path, test_path, sample_sub_path)
        print(f"Data loading: {time.time()-start_time:.2f}s")
        
        # Feature engineering
        start_time = time.time()
        predictor.train_df = predictor.engineer_features_vectorized(predictor.train_df)
        print(f"Feature engineering: {time.time()-start_time:.2f}s")
        
        # Data preparation
        start_time = time.time()
        X, y = predictor.prepare_data_optimized()
        print(f"Data preparation: {time.time()-start_time:.2f}s")
        
        # Model training
        start_time = time.time()
        predictor.train_model_optimized(X, y)
        print(f"Model training: {time.time()-start_time:.2f}s")
        
        # Test data preparation
        start_time = time.time()
        predictor.test_df = predictor.engineer_features_vectorized(predictor.test_df)
        print(f"Test feature engineering: {time.time()-start_time:.2f}s")
        
        # Predictions
        start_time = time.time()
        predictions = predictor.predict_optimized(predictor.test_df)
        print(f"Prediction: {time.time()-start_time:.2f}s")
        
        # Submission
        start_time = time.time()
        submission = predictor.create_submission_optimized(predictions)
        print(f"Submission creation: {time.time()-start_time:.2f}s")
        
        total_time = time.time() - total_start
        print(f"\n Total execution time: {total_time:.2f}s")
        print(f"Submission preview:")
        print(submission.head())
        
    except Exception as e:
        print(f"Error during execution: {e}")
        raise
    finally:
        # Cleanup
        gc.collect()
        tf.keras.backend.clear_session()

if __name__ == "__main__":
    main()
